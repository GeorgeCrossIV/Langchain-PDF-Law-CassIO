{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeCrossIV/Langchain-PDF-Law-CassIO/blob/main/Langchain_with_PDF_using_cassio_Law_cases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLHkt-bMq4up"
      },
      "source": [
        "# Langchain Retrieval Augmentation (using Law data)\n",
        "This notebook provides an example of using a PDF to create embeddings and ultimately enable a user to ask questions regarding the contents of the PDF."
      ],
      "id": "oLHkt-bMq4up"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUeV_S5q4u0"
      },
      "source": [
        "## Colab-specific setup"
      ],
      "id": "WQUeV_S5q4u0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1p8iUgjq4u2"
      },
      "source": [
        "Make sure you have a Database and get ready to upload the Secure Connect Bundle and supply the Token string\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#vector-database) on cassio.org for details).\n",
        "\n",
        "Likewise, ensure you have the necessary secret for the LLM provider of your choice: you'll be asked to input it shortly\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for details).\n",
        "\n",
        "_Note: some portions of this notebook is part of the CassIO documentation. Visit [this page on cassIO.org](https://cassio.org/frameworks/langchain/qa-basic/)._\n"
      ],
      "id": "Z1p8iUgjq4u2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2953d95b"
      },
      "outputs": [],
      "source": [
        "# install required dependencies\n",
        "! pip install \\\n",
        "    \"langchain\" \\\n",
        "    \"cassandra-driver>=3.28.0\" \\\n",
        "    \"cassio\" \\\n",
        "    \"google-cloud-aiplatform>=1.25.0\" \\\n",
        "    \"jupyter>=1.0.0\" \\\n",
        "    \"openai==0.27.7\" \\\n",
        "    \"tiktoken==0.4.0\" \\\n",
        "    \"pypdf\""
      ],
      "id": "2953d95b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "222f44ff"
      },
      "source": [
        "You will likely be asked to \"Restart the Runtime\" at this time, as some dependencies\n",
        "have been upgraded. **Please do restart the runtime now** for a smoother execution from this point onward."
      ],
      "id": "222f44ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTebGKsNENFZ"
      },
      "source": [
        "#Load a PDF file"
      ],
      "id": "VTebGKsNENFZ"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/GeorgeCrossIV/CassIO---PDF-Law-case-questions/raw/main/McCall-v-Microsoft.pdf\""
      ],
      "metadata": {
        "id": "hm1dj0_nOigq"
      },
      "id": "hm1dj0_nOigq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ls2QCj9GEa8U"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader('McCall-v-Microsoft.pdf')\n",
        "pages = loader.load_and_split()"
      ],
      "id": "Ls2QCj9GEa8U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZS2Xsy0WY-c"
      },
      "source": [
        "# Configure the Astra DB Connection"
      ],
      "id": "eZS2Xsy0WY-c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh4P-XUDq4u9"
      },
      "outputs": [],
      "source": [
        "# Input your database keyspace name:\n",
        "ASTRA_DB_KEYSPACE = input('Your Astra DB Keyspace name: ')"
      ],
      "id": "zh4P-XUDq4u9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThGqYchq4u-"
      },
      "outputs": [],
      "source": [
        "# Input your Astra DB token string, the one starting with \"AstraCS:...\"\n",
        "ASTRA_DB_TOKEN_BASED_PASSWORD = input('Your Astra DB Token: ')"
      ],
      "id": "lThGqYchq4u-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNQ6T_Gjk0Oz"
      },
      "source": [
        "### Astra DB Secure Connect Bundle\n",
        "\n",
        "Please upload the Secure Connect Bundle zipfile to connect to your Astra DB instance.\n",
        "\n",
        "The Secure Connect Bundle is needed to establish a secure connection to the database.\n",
        "Click [here](https://awesome-astra.github.io/docs/pages/astra/download-scb/#c-procedure) for instructions on how to download it from Astra DB."
      ],
      "id": "QNQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnNziXZ1q4vD"
      },
      "outputs": [],
      "source": [
        "# Upload your Secure Connect Bundle zipfile:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    ASTRA_DB_SECURE_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )"
      ],
      "id": "xnNziXZ1q4vD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUDw-07Iq4vE"
      },
      "outputs": [],
      "source": [
        "# colab-specific override of helper functions\n",
        "from cassandra.cluster import (\n",
        "    Cluster,\n",
        ")\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "# The \"username\" is the literal string 'token' for this connection mode:\n",
        "ASTRA_DB_TOKEN_BASED_USERNAME = 'token'\n",
        "\n",
        "\n",
        "def getCQLSession(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        cluster = Cluster(\n",
        "            cloud={\n",
        "                \"secure_connect_bundle\": ASTRA_DB_SECURE_BUNDLE_PATH,\n",
        "            },\n",
        "            auth_provider=PlainTextAuthProvider(\n",
        "                ASTRA_DB_TOKEN_BASED_USERNAME,\n",
        "                ASTRA_DB_TOKEN_BASED_PASSWORD,\n",
        "            ),\n",
        "        )\n",
        "        astraSession = cluster.connect()\n",
        "        return astraSession\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getCQLKeyspace(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        return ASTRA_DB_KEYSPACE\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')"
      ],
      "id": "TUDw-07Iq4vE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCQ6T_Gjk0Oz"
      },
      "source": [
        "### LLM Provider\n",
        "\n",
        "In the cell below you can choose between **GCP VertexAI** or **OpenAI** for your LLM services.\n",
        "(See [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for more details).\n",
        "\n",
        "Make sure you set the `llmProvider` variable and supply the corresponding access secrets in the following cell."
      ],
      "id": "QXCQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGpzZc5zq4vG"
      },
      "outputs": [],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = 'OpenAI'  # 'GCP_VertexAI'"
      ],
      "id": "pGpzZc5zq4vG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOFStlEAq4vH"
      },
      "outputs": [],
      "source": [
        "if llmProvider == 'OpenAI':\n",
        "    apiSecret = input(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['OPENAI_API_KEY'] = apiSecret\n",
        "elif llmProvider == 'GCP_VertexAI':\n",
        "    # we need a json file\n",
        "    print(f'Please upload your Service Account JSON for the LLM provider \"{llmProvider}\":')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        vertexAIJsonFileTitle = list(uploaded.keys())[0]\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.getcwd(), vertexAIJsonFileTitle)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'No file uploaded. Please re-run the cell.'\n",
        "        )\n",
        "else:\n",
        "    raise ValueError('Unknown/unsupported LLM Provider')"
      ],
      "id": "zOFStlEAq4vH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "# Vector Similarity Search QA Quickstart"
      ],
      "id": "6715bc2b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "761d9b70"
      },
      "source": [
        "_**NOTE:** this uses Cassandra's \"Vector Similarity Search\" capability.\n",
        "Make sure you are connecting to a vector-enabled database for this demo._"
      ],
      "id": "761d9b70"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "042f832e"
      },
      "outputs": [],
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import (\n",
        "    CharacterTextSplitter,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.vectorstores.cassandra import Cassandra"
      ],
      "id": "042f832e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4578a87b"
      },
      "source": [
        "A database connection is needed to access Cassandra. The following assumes\n",
        "that a _vector-search-capable Astra DB instance_ is available. Adjust as needed."
      ],
      "id": "4578a87b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11013224"
      },
      "outputs": [],
      "source": [
        "# creation of the DB connection\n",
        "cqlMode = 'astra_db'\n",
        "session = getCQLSession(mode=cqlMode)\n",
        "keyspace = getCQLKeyspace(mode=cqlMode)"
      ],
      "id": "11013224"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32e2a156"
      },
      "source": [
        "Both an LLM and an embedding function are required.\n",
        "\n",
        "Below is the logic to instantiate the LLM and embeddings of choice. We choose to leave it in the notebooks for clarity."
      ],
      "id": "32e2a156"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "124e3de4"
      },
      "outputs": [],
      "source": [
        "# creation of the LLM resources\n",
        "\n",
        "if llmProvider == 'GCP_VertexAI':\n",
        "    from langchain.llms import VertexAI\n",
        "    from langchain.embeddings import VertexAIEmbeddings\n",
        "    llm = VertexAI()\n",
        "    myEmbedding = VertexAIEmbeddings()\n",
        "    print('LLM+embeddings from VertexAI')\n",
        "elif llmProvider == 'OpenAI':\n",
        "    from langchain.llms import OpenAI\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    llm = OpenAI(temperature=0)\n",
        "    myEmbedding = OpenAIEmbeddings()\n",
        "    print('LLM+embeddings from OpenAI')\n",
        "else:\n",
        "    raise ValueError('Unknown LLM provider.')"
      ],
      "id": "124e3de4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "285f29cf"
      },
      "source": [
        "## Langchain Retrieval Augmentation"
      ],
      "id": "285f29cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cf74a31"
      },
      "source": [
        "The following is a minimal usage of the Cassandra vector store. The store is created and filled at once, and is then queried to retrieve relevant parts of the indexed text, which are then stuffed into a prompt finally used to answer a question."
      ],
      "id": "5cf74a31"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f29fc57"
      },
      "source": [
        "The following creates an \"index creator\", which knows about the type of vector store, the embedding to use and how to preprocess the input text:\n",
        "\n",
        "_(Note: stores built with different embedding functions will need different tables. This is why we append the `llmProvider` name to the table name in the next cell.)_"
      ],
      "id": "6f29fc57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2cfe71b"
      },
      "outputs": [],
      "source": [
        "table_name = 'vs_law_pdf_' + llmProvider\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Cassandra,\n",
        "    embedding=myEmbedding,\n",
        "    text_splitter=CharacterTextSplitter(\n",
        "        chunk_size=400,\n",
        "        chunk_overlap=0,\n",
        "    ),\n",
        "    vectorstore_kwargs={\n",
        "        'session': session,\n",
        "        'keyspace': keyspace,\n",
        "        'table_name': table_name,\n",
        "    },\n",
        ")"
      ],
      "id": "d2cfe71b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7V7uPgvE3yY"
      },
      "source": [
        "Create the Cassandra Vector Store and clear entries if the table already exists"
      ],
      "id": "C7V7uPgvE3yY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCxWxjRWl8Dg"
      },
      "outputs": [],
      "source": [
        "myCassandraVStore = Cassandra(\n",
        "    embedding=myEmbedding,\n",
        "    session=session,\n",
        "    keyspace=keyspace,\n",
        "    table_name=table_name,\n",
        ")\n",
        "\n",
        "myCassandraVStore.clear()"
      ],
      "id": "SCxWxjRWl8Dg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ITWD1pqmgeu"
      },
      "outputs": [],
      "source": [
        "mySplitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=120)"
      ],
      "id": "6ITWD1pqmgeu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVE2Mf2rFEvp"
      },
      "outputs": [],
      "source": [
        "for page in pages:\n",
        "  page_chunks = mySplitter.transform_documents([page])\n",
        "  myCassandraVStore.add_documents(page_chunks)"
      ],
      "id": "bVE2Mf2rFEvp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fySPtKkYmAgh"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndexWrapper(vectorstore=myCassandraVStore)"
      ],
      "id": "fySPtKkYmAgh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRiU4IMkF6di"
      },
      "source": [
        "Let's ask some questions about the PDF we loaded"
      ],
      "id": "tRiU4IMkF6di"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_96yaY45OFw"
      },
      "outputs": [],
      "source": [
        "query = \"What is the background of the McCall v. Microsoft Corp. case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "id": "S_96yaY45OFw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjNaRKGENLAz"
      },
      "outputs": [],
      "source": [
        "query = \"Who were the key parties involved in the case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "id": "XjNaRKGENLAz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JpmtYZMy2ur"
      },
      "outputs": [],
      "source": [
        "query = \"What was the verdict?\"\n",
        "index.query(query,llm=llm)"
      ],
      "id": "2JpmtYZMy2ur"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmIdlZngKvtU"
      },
      "source": [
        "You've now seen how we can use a LLM to answer the prompt from our Astra Vector Store, but notice that the answer is different from using the LLM directly."
      ],
      "id": "GmIdlZngKvtU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DikzwEj0Gawb"
      },
      "source": [
        "Let's get some information about the source for the response to the question \"What temperature should Andouille be cooked?\""
      ],
      "id": "DikzwEj0Gawb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5MrZWD7uaBa"
      },
      "outputs": [],
      "source": [
        "retriever = index.vectorstore.as_retriever(search_kwargs={\n",
        "    'k': 2,\n",
        "})"
      ],
      "id": "a5MrZWD7uaBa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg1FUbYoudSr"
      },
      "outputs": [],
      "source": [
        "retriever.get_relevant_documents(\n",
        "    \"What temperature should Andouille be cooked?\"\n",
        ")"
      ],
      "id": "dg1FUbYoudSr"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}