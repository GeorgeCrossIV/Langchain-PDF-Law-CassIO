{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeCrossIV/Langchain-PDF-Law-CassIO/blob/main/Langchain_with_PDF_using_cassio_Law_cases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLHkt-bMq4up"
      },
      "source": [
        "# Langchain Retrieval Augmentation (using Law data)\n",
        "Large Language Models (LLMs) have a data freshness problem. The most powerful LLMs in the world, like GPT-4, have no idea about recent world events.\n",
        "\n",
        "The world of LLMs is frozen in time. Their world exists as a static snapshot of the world as it was within their training data.\n",
        "\n",
        "A solution to this problem is retrieval augmentation. The idea behind this is that we retrieve relevant information from an external knowledge base and give that information to our LLM. In this notebook we will learn how to do that. In this demo, external or proprietary data will be stored in Astra DB and used to provide more current LLM responses."
      ],
      "id": "oLHkt-bMq4up"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUeV_S5q4u0"
      },
      "source": [
        "## Colab-specific setup"
      ],
      "id": "WQUeV_S5q4u0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1p8iUgjq4u2"
      },
      "source": [
        "Make sure you have a Database and get ready to upload the Secure Connect Bundle and supply the Token string\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#vector-database) on cassio.org for details).\n",
        "\n",
        "Likewise, ensure you have the necessary secret for the LLM provider of your choice: you'll be asked to input it shortly\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for details).\n",
        "\n",
        "_Note: some portions of this notebook is part of the CassIO documentation. Visit [this page on cassIO.org](https://cassio.org/frameworks/langchain/qa-basic/)._\n"
      ],
      "id": "Z1p8iUgjq4u2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2953d95b",
      "metadata": {
        "id": "2953d95b"
      },
      "outputs": [],
      "source": [
        "# install required dependencies\n",
        "! pip install \\\n",
        "    \"langchain\" \\\n",
        "    \"cassandra-driver>=3.28.0\" \\\n",
        "    \"cassio\" \\\n",
        "    \"google-cloud-aiplatform>=1.25.0\" \\\n",
        "    \"jupyter>=1.0.0\" \\\n",
        "    \"openai==0.27.7\" \\\n",
        "    \"tiktoken==0.4.0\" \\\n",
        "    \"pypdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222f44ff",
      "metadata": {
        "id": "222f44ff"
      },
      "source": [
        "You will likely be asked to \"Restart the Runtime\" at this time, as some dependencies\n",
        "have been upgraded. **Please do restart the runtime now** for a smoother execution from this point onward."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load a PDF file"
      ],
      "metadata": {
        "id": "VTebGKsNENFZ"
      },
      "id": "VTebGKsNENFZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your PDF document:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print('Please upload a PDF to train')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    pdfFileTitle = list(uploaded.keys())[0]\n",
        "    PDF_PATH = os.path.join(os.getcwd(), pdfFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed loading a PDF file. Please re-run the cell.'\n",
        "    )"
      ],
      "metadata": {
        "id": "vfWxOITlDs9x"
      },
      "id": "vfWxOITlDs9x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(PDF_PATH)\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "Ls2QCj9GEa8U"
      },
      "id": "Ls2QCj9GEa8U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "id": "Pf30RVLSEhsP"
      },
      "id": "Pf30RVLSEhsP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the Astra DB Connection"
      ],
      "metadata": {
        "id": "eZS2Xsy0WY-c"
      },
      "id": "eZS2Xsy0WY-c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh4P-XUDq4u9"
      },
      "outputs": [],
      "source": [
        "# Input your database keyspace name:\n",
        "ASTRA_DB_KEYSPACE = input('Your Astra DB Keyspace name: ')"
      ],
      "id": "zh4P-XUDq4u9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUt_WX6_xwUP"
      },
      "id": "nUt_WX6_xwUP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThGqYchq4u-"
      },
      "outputs": [],
      "source": [
        "# Input your Astra DB token string, the one starting with \"AstraCS:...\"\n",
        "ASTRA_DB_TOKEN_BASED_PASSWORD = input('Your Astra DB Token: ')"
      ],
      "id": "lThGqYchq4u-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNQ6T_Gjk0Oz"
      },
      "source": [
        "### Astra DB Secure Connect Bundle\n",
        "\n",
        "Please upload the Secure Connect Bundle zipfile to connect to your Astra DB instance.\n",
        "\n",
        "The Secure Connect Bundle is needed to establish a secure connection to the database.\n",
        "Click [here](https://awesome-astra.github.io/docs/pages/astra/download-scb/#c-procedure) for instructions on how to download it from Astra DB."
      ],
      "id": "QNQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnNziXZ1q4vD"
      },
      "outputs": [],
      "source": [
        "# Upload your Secure Connect Bundle zipfile:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    ASTRA_DB_SECURE_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )"
      ],
      "id": "xnNziXZ1q4vD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUDw-07Iq4vE"
      },
      "outputs": [],
      "source": [
        "# colab-specific override of helper functions\n",
        "from cassandra.cluster import (\n",
        "    Cluster,\n",
        ")\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "# The \"username\" is the literal string 'token' for this connection mode:\n",
        "ASTRA_DB_TOKEN_BASED_USERNAME = 'token'\n",
        "\n",
        "\n",
        "def getCQLSession(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        cluster = Cluster(\n",
        "            cloud={\n",
        "                \"secure_connect_bundle\": ASTRA_DB_SECURE_BUNDLE_PATH,\n",
        "            },\n",
        "            auth_provider=PlainTextAuthProvider(\n",
        "                ASTRA_DB_TOKEN_BASED_USERNAME,\n",
        "                ASTRA_DB_TOKEN_BASED_PASSWORD,\n",
        "            ),\n",
        "        )\n",
        "        astraSession = cluster.connect()\n",
        "        return astraSession\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getCQLKeyspace(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        return ASTRA_DB_KEYSPACE\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')"
      ],
      "id": "TUDw-07Iq4vE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCQ6T_Gjk0Oz"
      },
      "source": [
        "### LLM Provider\n",
        "\n",
        "In the cell below you can choose between **GCP VertexAI** or **OpenAI** for your LLM services.\n",
        "(See [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for more details).\n",
        "\n",
        "Make sure you set the `llmProvider` variable and supply the corresponding access secrets in the following cell."
      ],
      "id": "QXCQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGpzZc5zq4vG"
      },
      "outputs": [],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = 'OpenAI'  # 'GCP_VertexAI'"
      ],
      "id": "pGpzZc5zq4vG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOFStlEAq4vH"
      },
      "outputs": [],
      "source": [
        "if llmProvider == 'OpenAI':\n",
        "    apiSecret = input(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['OPENAI_API_KEY'] = apiSecret\n",
        "elif llmProvider == 'GCP_VertexAI':\n",
        "    # we need a json file\n",
        "    print(f'Please upload your Service Account JSON for the LLM provider \"{llmProvider}\":')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        vertexAIJsonFileTitle = list(uploaded.keys())[0]\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.getcwd(), vertexAIJsonFileTitle)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'No file uploaded. Please re-run the cell.'\n",
        "        )\n",
        "else:\n",
        "    raise ValueError('Unknown/unsupported LLM Provider')"
      ],
      "id": "zOFStlEAq4vH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0rYQTmwq4vI"
      },
      "source": [
        "### Colab preamble completed\n",
        "\n",
        "The following cells constitute the demo notebook proper."
      ],
      "id": "W0rYQTmwq4vI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test - using Facebook AI Search"
      ],
      "metadata": {
        "id": "j_8_xdFMGa1b"
      },
      "id": "j_8_xdFMGa1b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "q4VuPMIsHecf"
      },
      "id": "q4VuPMIsHecf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
        "docs = faiss_index.similarity_search(\"What is Account Management?\", k=2)\n",
        "for doc in docs:\n",
        "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
      ],
      "metadata": {
        "id": "eKT4milTGfUy"
      },
      "id": "eKT4milTGfUy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6715bc2b",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "# Vector Similarity Search QA Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761d9b70",
      "metadata": {
        "id": "761d9b70"
      },
      "source": [
        "_**NOTE:** this uses Cassandra's \"Vector Similarity Search\" capability.\n",
        "Make sure you are connecting to a vector-enabled database for this demo._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042f832e",
      "metadata": {
        "id": "042f832e"
      },
      "outputs": [],
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import (\n",
        "    CharacterTextSplitter,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4388ac1d",
      "metadata": {
        "id": "4388ac1d"
      },
      "source": [
        "The following line imports the Cassandra flavor of a LangChain vector store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65c46f0",
      "metadata": {
        "id": "d65c46f0"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4578a87b",
      "metadata": {
        "id": "4578a87b"
      },
      "source": [
        "A database connection is needed to access Cassandra. The following assumes\n",
        "that a _vector-search-capable Astra DB instance_ is available. Adjust as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11013224",
      "metadata": {
        "id": "11013224"
      },
      "outputs": [],
      "source": [
        "# creation of the DB connection\n",
        "cqlMode = 'astra_db'\n",
        "session = getCQLSession(mode=cqlMode)\n",
        "keyspace = getCQLKeyspace(mode=cqlMode)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e2a156",
      "metadata": {
        "id": "32e2a156"
      },
      "source": [
        "Both an LLM and an embedding function are required.\n",
        "\n",
        "Below is the logic to instantiate the LLM and embeddings of choice. We choose to leave it in the notebooks for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "124e3de4",
      "metadata": {
        "id": "124e3de4"
      },
      "outputs": [],
      "source": [
        "# creation of the LLM resources\n",
        "\n",
        "if llmProvider == 'GCP_VertexAI':\n",
        "    from langchain.llms import VertexAI\n",
        "    from langchain.embeddings import VertexAIEmbeddings\n",
        "    llm = VertexAI()\n",
        "    myEmbedding = VertexAIEmbeddings()\n",
        "    print('LLM+embeddings from VertexAI')\n",
        "elif llmProvider == 'OpenAI':\n",
        "    from langchain.llms import OpenAI\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    llm = OpenAI(temperature=0)\n",
        "    myEmbedding = OpenAIEmbeddings()\n",
        "    print('LLM+embeddings from OpenAI')\n",
        "else:\n",
        "    raise ValueError('Unknown LLM provider.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "285f29cf",
      "metadata": {
        "id": "285f29cf"
      },
      "source": [
        "## Langchain Retrieval Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf74a31",
      "metadata": {
        "id": "5cf74a31"
      },
      "source": [
        "The following is a minimal usage of the Cassandra vector store. The store is created and filled at once, and is then queried to retrieve relevant parts of the indexed text, which are then stuffed into a prompt finally used to answer a question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f29fc57",
      "metadata": {
        "id": "6f29fc57"
      },
      "source": [
        "The following creates an \"index creator\", which knows about the type of vector store, the embedding to use and how to preprocess the input text:\n",
        "\n",
        "_(Note: stores built with different embedding functions will need different tables. This is why we append the `llmProvider` name to the table name in the next cell.)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2cfe71b",
      "metadata": {
        "id": "d2cfe71b"
      },
      "outputs": [],
      "source": [
        "table_name = 'vs_law_pdf_' + llmProvider\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Cassandra,\n",
        "    embedding=myEmbedding,\n",
        "    text_splitter=CharacterTextSplitter(\n",
        "        chunk_size=400,\n",
        "        chunk_overlap=0,\n",
        "    ),\n",
        "    vectorstore_kwargs={\n",
        "        'session': session,\n",
        "        'keyspace': keyspace,\n",
        "        'table_name': table_name,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Cassandra Vector Store and clear entries if the table already exists"
      ],
      "metadata": {
        "id": "C7V7uPgvE3yY"
      },
      "id": "C7V7uPgvE3yY"
    },
    {
      "cell_type": "code",
      "source": [
        "myCassandraVStore = Cassandra(\n",
        "    embedding=myEmbedding,\n",
        "    session=session,\n",
        "    keyspace=keyspace,\n",
        "    table_name=table_name,\n",
        ")\n",
        "\n",
        "myCassandraVStore.clear()"
      ],
      "metadata": {
        "id": "SCxWxjRWl8Dg"
      },
      "id": "SCxWxjRWl8Dg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mySplitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=120)"
      ],
      "metadata": {
        "id": "6ITWD1pqmgeu"
      },
      "id": "6ITWD1pqmgeu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the function for creating a vector index for a Wikipedia entry"
      ],
      "metadata": {
        "id": "oogCCCXcv3yG"
      },
      "id": "oogCCCXcv3yG"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_index_for_page(page, myCassandraVStore):\n",
        "  page_chunks = mySplitter.transform_documents(page)\n",
        "  myCassandraVStore.add_documents(page_chunks)"
      ],
      "metadata": {
        "id": "mbsblXxQwAT9"
      },
      "id": "mbsblXxQwAT9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the create_vector_index function for each row in the Wikipedia dataframe. It's good time to grab a drink as the next step will take about 90 seconds to complete."
      ],
      "metadata": {
        "id": "ZCXx5rKUxj_z"
      },
      "id": "ZCXx5rKUxj_z"
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(PDF_PATH)\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "print(pages[0])"
      ],
      "metadata": {
        "id": "M3K5EOR1xrdO"
      },
      "id": "M3K5EOR1xrdO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pages))"
      ],
      "metadata": {
        "id": "EW7UFRvdFMYp"
      },
      "id": "EW7UFRvdFMYp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for page in pages:\n",
        "  page_chunks = mySplitter.transform_documents([page])\n",
        "  myCassandraVStore.add_documents(page_chunks)"
      ],
      "metadata": {
        "id": "bVE2Mf2rFEvp"
      },
      "id": "bVE2Mf2rFEvp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndexWrapper(vectorstore=myCassandraVStore)"
      ],
      "metadata": {
        "id": "fySPtKkYmAgh"
      },
      "id": "fySPtKkYmAgh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's query our proprietory store. We'll ask \"What is Andouille?\""
      ],
      "metadata": {
        "id": "geA-eXncFwvi"
      },
      "id": "geA-eXncFwvi"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Account Management?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "cEp-I8wd5Abv"
      },
      "id": "cEp-I8wd5Abv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm really interested in what temperature to cook my andouille."
      ],
      "metadata": {
        "id": "tRiU4IMkF6di"
      },
      "id": "tRiU4IMkF6di"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the background of the McCall v. Microsoft Corp. case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "S_96yaY45OFw"
      },
      "id": "S_96yaY45OFw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who were the key parties involved in the case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "XjNaRKGENLAz"
      },
      "id": "XjNaRKGENLAz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who were the plaintiffs and who were the defendants?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "2JpmtYZMy2ur"
      },
      "execution_count": null,
      "outputs": [],
      "id": "2JpmtYZMy2ur"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare this answer to what OpenAi GPT-3 will return"
      ],
      "metadata": {
        "id": "4uJebWz9JfAu"
      },
      "id": "4uJebWz9JfAu"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = apiSecret\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-003\",\n",
        "  prompt=\"What is the background of the McCall v. Microsoft Corp. case?\",\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "print(response.choices[0].text.strip())"
      ],
      "metadata": {
        "id": "zX48Pu3-Jl9B"
      },
      "id": "zX48Pu3-Jl9B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You've now seen how we can use a LLM to answer the prompt from our Astra Vector Store, but notice that the answer is different from using the LLM directly."
      ],
      "metadata": {
        "id": "GmIdlZngKvtU"
      },
      "id": "GmIdlZngKvtU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get some information about the source for the response to the question \"What temperature should Andouille be cooked?\""
      ],
      "metadata": {
        "id": "DikzwEj0Gawb"
      },
      "id": "DikzwEj0Gawb"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.vectorstore.as_retriever(search_kwargs={\n",
        "    'k': 2,\n",
        "})"
      ],
      "metadata": {
        "id": "a5MrZWD7uaBa"
      },
      "id": "a5MrZWD7uaBa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\n",
        "    \"What temperature should Andouille be cooked?\"\n",
        ")"
      ],
      "metadata": {
        "id": "dg1FUbYoudSr"
      },
      "id": "dg1FUbYoudSr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}